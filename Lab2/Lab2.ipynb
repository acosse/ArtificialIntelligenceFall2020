{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Lab II: Search Methods and Search Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. Escaping from Mazes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1 \n",
    "\n",
    "Consider the maze shown below. The yellow cells represent the walls. We want to find the way from node $A$ located in cell (0,7) (bottom left) to $B$ located in cell (8,0) (top right). Implement a Depth First Search that would escape from the maze and reach position $B$. Start by building the graph corresponding to the feasible paths (i.e. connecting the blue cells). Then implement DFS and apply it, starting with $A$ as your root node.\n",
    "\n",
    "You may want to implement functions ind2num and ind2num to go back and forth between the number of the cell and its position on the grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBxIjMCBxAgcSOx/nUGfyQcgLb8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Maze = sio.loadmat('MazeMat.mat')['MazeMat']\n",
    "plt.imshow(Maze)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2 Repeat the exercise with Breadth First Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3 Informed escape.\n",
    "\n",
    "We now want to implement an informed search method. Code the A$^*$ search algorithm using as your heuristic the distance as the crow flies between the current node and the objective node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4 \n",
    "\n",
    "Test your algorithms on the Maze below. Starting from the yellow square and trying of reach the exit (light blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAADJVJREFUeJzt3X+o3fV9x/HnyyyaajdsqAuZcatr\n3YqMmkJmLevA6RyZ/6hQSh0tGQhxUKEFGc36T3+wgoVZ+88opNSZP7pasXXKcHXBBVxhpFqb2qjt\nTJ2lyWLSYqWxhayJ7/1xvoGbeK85nvM9555zPs8HXM45n3PO/b6/ufeVz7mf8z3fd6oKSe05Z7UL\nkLQ6DL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40aK/xJtib5YZIDSXb0VZSkycuoR/glWQP8N3Ad\ncBB4HLi5qp5Z6Tnn5rxaxwUjbU/Sax2/5PQ8nXjpJU6+8ssM89zfGGO7VwIHqup5gCT3AjcAK4Z/\nHRfwnlw7xiYlLXXg9qtOu/2/d35h6OeO87L/YuAnS24f7MYkzYFxZv6hJNkObAdYx/mT3pykIY0z\n8x8CLllye1M3dpqq2llVW6pqy1rOG2Nzkvo0zsz/OHBZkksZhP6DwF/1UpWkofzOY6cv2P/02PDP\nHTn8VXUiyW3AI8Aa4O6qenrU7ydpusb6m7+qHgYe7qkWSVPkEX5Sowy/1CjDLzVq4u/zq3+/uuk9\nrxk7/4G9q1CJ5pkzv9Qowy81yvBLjTL8UqNc8NPCW26BVM78UrMMv9Qowy81yvBLjTL8UqNc7VeT\nFvVw6HPql8M/doJ1SJphhl9qlOGXGmX4pUaNteCX5AXgGHASOFFVW/ooaiUepin1p4/V/j+rqp/1\n8H0kTZEv+6VGjRv+Av49yXe6tlyvkWR7kieSPPFrjo+5OUl9Gfdl//uq6lCS3wZ2J/lBVT229AFV\ntRPYCfBbWT9aP3BJvRtr5q+qQ93lUeABBm27Jc2BkWf+JBcA51TVse76XwCf6a2yN2BRD9Vcie96\nqA/jvOzfADyQ5NT3+eeq+mYvVUmauHEadT4PXNFjLZKmyLf6pEYZfqlRhl9qlOGXGmX4pUYZfqlR\nhl9qlOGXGuXZe9WkPg6RnvfDyp35pUYZfqlRhl9qlOGXGuWCn5o074t1fXDmlxpl+KVGGX6pUYZf\natRZw5/k7iRHk+xfMrY+ye4kz3WXb5lsmZL6NszMfw+w9YyxHcCjVXUZ8Gh3W9IcOWv4uyYcL50x\nfAOwq7u+C7ix57okTdio7/NvqKrD3fUXGZzGe1ldG6/tAOs4f8TNSerb2At+VVUMevatdP/OqtpS\nVVvWct64m5PUk1HDfyTJRoDu8mh/JUmahlFf9j8EbAPu6C4f7K2iGTerrbJmtS7NrmHe6vsq8F/A\nHyY5mOQWBqG/LslzwJ93tyXNkbPO/FV18wp3XdtzLZKmyCP8pEYZfqlRfp6/B619NnylxcVZ/Xdw\nMXR5zvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjD\nLzVq1HZdn0pyKMm+7uv6yZYpqW+jtusCuKuqNndfD/dblqRJG7Vdl6Q5N87f/Lclear7s8AuvdKc\nGTX8XwTeDmwGDgN3rvTAJNuTPJHkiV9zfMTNSerbSOGvqiNVdbKqXgW+BFz5Oo+1V580g0Y6e2+S\njUu69N4E7H+9x0uzZpbP6DutsyCfNfxdu66rgbcmOQh8Erg6yWYG3XlfAG6dYI2SJmDUdl1fnkAt\nkqbII/ykRhl+qVGGX2qUvfrUpFntKzhNzvxSowy/1CjDLzXK8EuNcsGvB7N8qOi4XBhbXM78UqMM\nv9Qowy81yvBLjTL8UqNc7e/BoqyIL/euxSK/k9E6Z36pUYZfapThlxo1TLuuS5LsSfJMkqeTfLQb\nX59kd5LnukvP3S/NkWEW/E4At1fVk0l+E/hOkt3AXwOPVtUdSXYAO4CPT65UTdqwC5cuAi6GYdp1\nHa6qJ7vrx4BngYuBG4Bd3cN2ATdOqkhJ/XtDf/MneRvwbmAvsGHJuftfBDb0WpmkiRo6/EneDHwd\n+FhV/WLpfVVVDM7hv9zzbNclzaChwp9kLYPgf6WqvtENH0mysbt/I3B0uefarkuaTcOs9odBk45n\nq+rzS+56CNjWXd8GPNh/eZImZZjV/j8BPgx8P8m+buwTwB3AfUluAX4MfGAyJUqahGHadX0LyAp3\nX9tvOZKmxSP8pEYZfqlRhl9q1EJ8nt/DTaU3zplfapThlxpl+KVGGX6pUXO14DcLJ8p0cXExzPLP\ncVq/5878UqMMv9Qowy81yvBLjTL8UqPmarVfGsUsvEu0nJXecVhufBL74MwvNcrwS40y/FKjxmnX\n9akkh5Ls676un3y5kvoyTrsugLuq6h8mV560uFZaxJvWocfDnMDzMHC4u34syal2XZLm2DjtugBu\nS/JUkrvt0ivNl3HadX0ReDuwmcErgztXeJ7tuqQZNHK7rqo6UlUnq+pV4EvAlcs913Zd0mwauV3X\nqT59nZuA/f2XJ2lSxmnXdXOSzQy6874A3DqRCufALJwYYlYPYdXsGqdd18P9lyNpWjzCT2qU4Zca\nZfilRvl5/h642KZ55MwvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/U\nKMMvNcrwS40a5gSe65J8O8n3unZdn+7GL02yN8mBJF9Lcu7ky5XUl2Fm/uPANVV1BYNz9G9NchXw\nOQbtut4B/By4ZXJlSurbWcNfA690N9d2XwVcA9zfje8CbpxIhZImYtimHWu603YfBXYDPwJerqoT\n3UMOYv8+aa4MFf6uM89mYBODzjzvHHYDtuuSZtMbWu2vqpeBPcB7gQuTnDoH4Cbg0ArPsV2XNIOG\nWe2/KMmF3fU3AdcBzzL4T+D93cO2AQ9OqkhJ/Rvm7L0bgV1J1jD4z+K+qvrXJM8A9yb5e+C7DPr5\nTdQstMXSyvz5rGwWz/A8TLuup4B3LzP+PCt05pU0+zzCT2qU4ZcaZfilRi1Eu65ZXExZZLP8773c\nouM0611p0XMWF0Od+aVGGX6pUYZfapThlxpl+KVGLcRqvzQrZvmdkDM580uNMvxSowy/1CjDLzXK\n8EuNMvxSowy/1CjDLzXK8EuNGqdX3z1J/ifJvu5r8+TLldSXYQ7vPdWr75Uka4FvJfm37r6/rar7\nX+e5kmbUMGfvLWC5Xn2S5thIvfqq6tSnFz6b5KkkdyVZth2P7bqk2TRSr74kfwT8HYOefX8MrAc+\nvsJzbdclzaBRe/VtrarDXfvu48A/YQMPaa6M2qvvB0k2dmMBbgT2T7JQSf0ap1fffyS5CAiwD/ib\nCdYpqWfj9Oq7ZiIVSZoKj/CTGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlR\nhl9qlOGXGmX4pUYN83n+3vzBu37FI4/sO23sTz9y6zRL0II7/4G9Z3+QAGd+qVmGX2qU4ZcaZfil\nRmXQkGdKG0t+Cvy4u/lW4GdT2/j0uF/zZ5H27feq6qJhHjjV8J+24eSJqtqyKhufIPdr/izyvr0e\nX/ZLjTL8UqNWM/w7V3Hbk+R+zZ9F3rcVrdrf/JJWly/7pUZNPfxJtib5YZIDSXZMe/t9SnJ3kqNJ\n9i8ZW59kd5Lnusu3rGaNo0hySZI9SZ5J8nSSj3bjc71vSdYl+XaS73X79elu/NIke7vfya8lOXe1\na52GqYa/a/b5j8BfApcDNye5fJo19OweYOsZYzuAR6vqMuDR7va8OQHcXlWXA1cBH+l+TvO+b8eB\na6rqCmAzsDXJVcDngLuq6h3Az4FbVrHGqZn2zH8lcKCqnq+q/wPuBW6Ycg29qarHgJfOGL4B2NVd\n38WgfflcqarDVfVkd/0Y8CxwMXO+bzXwSndzbfdVwDXA/d343O3XqKYd/ouBnyy5fbAbWyQbqupw\nd/1FYMNqFjOuJG9j0KV5Lwuwb0nWJNkHHAV2Az8CXq6qE91DFvF3clku+E1QDd5Kmdu3U5K8Gfg6\n8LGq+sXS++Z136rqZFVtBjYxeCX6zlUuadVMO/yHgEuW3N7UjS2SI0k2AnSXR1e5npEkWcsg+F+p\nqm90wwuxbwBV9TKwB3gvcGGSUye2WcTfyWVNO/yPA5d1q6vnAh8EHppyDZP2ELCtu74NeHAVaxlJ\nkgBfBp6tqs8vuWuu9y3JRUku7K6/CbiOwXrGHuD93cPmbr9GNfWDfJJcD3wBWAPcXVWfnWoBPUry\nVeBqBp8KOwJ8EvgX4D7gdxl8gvEDVXXmouBMS/I+4D+B7wOvdsOfYPB3/9zuW5J3MVjQW8Ng4ruv\nqj6T5PcZLD6vB74LfKiqjq9epdPhEX5So1zwkxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZfatT/\nAxiRl+bnnJkqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Maze2 = sio.loadmat('mazeImage.mat')['mazeImage']\n",
    "plt.imshow(Maze2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5. From Escaping to Generating\n",
    "\n",
    "Depth First Search can actually be used to generate mazes. Follow the steps below to generate your own map.\n",
    "\n",
    "1. Choose the initial cell, mark it as visited and push it to the stack\n",
    "2. While the stack is not empty:\n",
    "\n",
    "    1. Pop a cell from the stack and make it a current cell\n",
    "    2. If the current cell has any neighbours which have not been visited Push the current        cell to the stack Choose one of the unvisited neighbours\n",
    "    3. Remove the wall between the current cell and the chosen cell\n",
    "    4. Mark the chosen cell as visited and push it to the stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MazeGeneration(n):\n",
    "    \n",
    "    '''the function should take as input the size of the maze and should return  \n",
    "    a starting point (location of PACMAN, P in yellow), an exit \n",
    "    location (E in light blue as above) and a binary image of the maze '''\n",
    "   \n",
    "\n",
    "\n",
    "    return Maze, P, E \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.6. Bidirectional Maze Generation\n",
    "\n",
    "Once you are done with 1.4., try to implement a Maze generating function that takes an input a \n",
    "PacMan location, an exit location, and a size parameter and return the binary image of the maze. (hint: use the bidirectional search approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Bidirectional_MazeGeneration(n, P, E):\n",
    "    \n",
    "        '''The function should take as input a starting point ('Pacman location'), \n",
    "        an Exit location 'E' and should return the image/map of the maze'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return Maze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. Improving our environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1. A maze escaping agent \n",
    "\n",
    "Now that you are comfortable with Search methods, Maze and object oriented programming, we want to combine the tools to define a basic search agent. \n",
    "\n",
    "The Escape Agent will inherit from the class Agent. It should have an initialization function which takes as argument the search method (as a string) that it is going to use to escape the maze. The list of possible inputs should include 'BFS', 'DFS', 'Astar', 'BF'. It should also contain an argument indicating the problem we want to solve (for the moment the only value this argument should take is 'escape'). Finally, for the informed search methods, it should contain the name of the heuristic used. We will consider two  heuristics which you should define as separate functions (outside the class):\n",
    "\n",
    "- The Manhattan distance. In this case, we will compute the estimated distance between our current state $(x_1, y_1)$ and the goal state $(x^*, y^*)$ through the so-called Manhattan distance\n",
    "$$|x_1 - x^*| + |y_1 - y^*|$$\n",
    " \n",
    "- The Euclidean distance. In this case, we will estimate the distance between our current state $(x_1, y_1)$ and the goal state $(x^*, y^*)$ through the Eulidean distance\n",
    "$$\\sqrt{|x_1 - x^*|^2 + |y_1 - y^*|^2}$$\n",
    "\n",
    "The Agent should also contain a function 'program' which takes as input the state of the environment (current position + list of admissible neighbors)\n",
    "\n",
    "\n",
    "The Maze environment should contain an initialization function which generates a random maze. This environment should also contain a function 'get_nextState' which for any given state returns the possible neighbors of that state. The 'program' function of the agent will then choose its next move among those states (possibly with the heuristic function).\n",
    "\n",
    "In this first exercise, the Agent should keep track of a list of actions (generated when the original state is given. At each step, it should then take its next action from the list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "'''Class should contain basic parameters common to all the agents'''    \n",
    "    \n",
    "    def __init__(self, program=None):\n",
    "        \n",
    "            self.actions = [] # should contain the list of actions as \n",
    "                              # returned by the search algorithm\n",
    "\n",
    "\n",
    "class EscapeAgent(Agent):\n",
    "    \n",
    "    '''The Escape Agent'''\n",
    "    \n",
    "    def __init__(self, SearchFun = 'DFS', problem = 'escape', heuristic = None):\n",
    "        \n",
    "        '''Function should initilize the agent with a Search Method and possible heuristic'''\n",
    "        self.searchMethod = SearchFun\n",
    "        \n",
    "    \n",
    "    def generateActions(self, initialState):\n",
    "        \n",
    "        # Apply the Search Method \n",
    "    \n",
    "        \n",
    "        return self.actions\n",
    "    \n",
    "    def program(self, state):\n",
    "        \n",
    "        \n",
    "        return self.actions[0]\n",
    "\n",
    "\n",
    "class MazeEnvironment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.agents = [] # should keep a list of agents\n",
    "        \n",
    "    def get_nextStates(self, state):\n",
    "        \n",
    "        '''Function should generate the neighboring states. \n",
    "        This function will be used later when adding other elements in the maze'''\n",
    "        \n",
    "    \n",
    "    \n",
    "    def step():\n",
    "        '''enable the agent to move one step: Take action from list of actions \n",
    "        and modify state of the environment'''\n",
    "    \n",
    "    \n",
    "    def addSearchAgent():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise 2.2. Testing\n",
    "\n",
    "Run your agent on various mazes generated through the environment and display the path followed by your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "maxStep = # choose a number of steps\n",
    "\n",
    "for step in range(0,maxStep):\n",
    "\n",
    "    MazeEnvironment.step()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3. Food\n",
    "\n",
    "We now want to improve the environment. The first improvement we will consider are food pellets. Those should be represented by green pixels on the path of the agent. The Food Agent should inherit all the search methods from the class SearchAgent but now, each time it found a food pellet, it should recompute the path to the next pellet. \n",
    "\n",
    "The MazeEnvironment_withFood class should thus encode the location of the food pellets and update the list of locations whenever the agents captured one of the pellets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class FoodAgent(SearchAgent):\n",
    "'''Class should contain basic parameters common to all the agents'''    \n",
    "    \n",
    "    def __init__(self, program=None):\n",
    "        \n",
    "        \n",
    "class MazeEnvironment_withFood:\n",
    "    \n",
    "    \n",
    "    self.status = [] # should be updated when \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "            '''should generate a maze with a few food pellets located on the path'''\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_nextStates(self, state):\n",
    "        \n",
    "        '''should return the neighbors of the current state'''\n",
    "        \n",
    "    \n",
    "    \n",
    "    def step():\n",
    "    \n",
    "    \n",
    "    def addSearchAgent():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3. Ghosts.\n",
    "\n",
    "A ghost is an additional (fixed) position on the path. When the agent notices it, it should backtrack and look for another path that avoids this ghost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Ghost:\n",
    "'''Class should contain '''    \n",
    "    \n",
    "    def __init__(self, position):\n",
    "        \n",
    "        self.position = position\n",
    "        \n",
    "        \n",
    "        \n",
    "class MazeEnvironment_withFood_and_Ghosts:\n",
    "    \n",
    "    \n",
    "    self.status = [] # should be updated when \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "            '''should generate a maze with a few food pellets and ghosts'''\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_nextStates(self, state):\n",
    "        \n",
    "        '''should return the neighbors of the current state'''\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def step():\n",
    "    \n",
    "    \n",
    "    def addSearchAgent():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4. \n",
    "\n",
    "Once you have successfully coded the fixed ghost framework, try to enable the ghosts to move throughout the maze. Concretely, this means you now update the position of the ghost at random (following from the set of connected neighbors). Note that a ghost can be located on top of a pellet. Only one of the two will be visible (except if you improve the display). Just keep track of both positions.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MazeEnvironment_withFood_and_MovingGhosts:\n",
    "    \n",
    "    \n",
    "    self.status = [] # should be updated when \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "            '''should generate a maze with a few food pellets and ghosts'''\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_nextStates(self, state):\n",
    "        \n",
    "        '''should return the neighbors of the current state'''\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def step():\n",
    "    \n",
    "        self.status = # update the positions of the ghosts \n",
    "        \n",
    "    \n",
    "    def addSearchAgent():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5. Visualization \n",
    "\n",
    "Update the environement of your choice to keep track of a list each frame. One possibility is for the function step to return the current frame. Then use matplotlib animation API (or any other movie generating library) to generate the movie of your agent's escape.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# put your code here \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
